from PIL import Image
import pytesseract
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import glob
import os
import cv2
import numpy as np

# Tesseract ì„¤ì¹˜ ê²½ë¡œ ì§€ì • (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# --- 1. ê¸°ì¡´ í•¨ìˆ˜ë“¤ (ìˆ˜ì • ì—†ìŒ) ---

def extract_text_from_image(image_path):
    try:
        stream = open(image_path, "rb")
        bytes = bytearray(stream.read())
        numpy_array = np.asarray(bytes, dtype=np.uint8)
        img_cv = cv2.imdecode(numpy_array, cv2.IMREAD_UNCHANGED)
        
        if img_cv is None:
            return f"ì˜¤ë¥˜ ë°œìƒ: OpenCVê°€ ì´ë¯¸ì§€ íŒŒì¼({os.path.basename(image_path)})ì„ ë””ì½”ë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        img_gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
        img_binary = cv2.adaptiveThreshold(
            img_gray, 
            maxValue=255, 
            adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            thresholdType=cv2.THRESH_BINARY, 
            blockSize=11, 
            C=2
        )
        img_pil = Image.fromarray(img_binary)
        text = pytesseract.image_to_string(img_pil, lang='kor')
        return text
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {e}"

def predict_risk(text):
    model_path = "./saved_model"
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)

    with torch.no_grad():
        logits = model(**inputs).logits

    prediction = torch.argmax(logits, dim=-1).item()
    label_map = {
        0: "ğŸš¨ ì „ì„¸ ì‚¬ê¸° ìœ„í—˜",
        1: "ğŸš¨ ì›”ì„¸ ë³´ì¦ê¸ˆ ì‚¬ê¸° ìœ„í—˜",
        2: "ğŸš¨ ë§¤ë§¤ ì‚¬ê¸° ìœ„í—˜",
        3: "âš ï¸ ê³µí†µ ìœ„í—˜ (ë“±ê¸°ë¶€ë“±ë³¸ í™•ì¸ í•„ìˆ˜)",
        4: "âœ… ì•ˆì „ / ì¼ë°˜ ì •ë³´"
    }
    result = label_map.get(prediction, "íŒë‹¨ ë¶ˆê°€")
    return result

# --- 2. ìƒˆë¡œ ì¶”ê°€í•  í•¨ìˆ˜ 2ê°œ ---

def find_risk_keywords(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ë¯¸ë¦¬ ì •ì˜ëœ ìœ„í—˜ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    risk_keywords = ["ê·¼ì €ë‹¹", "ì••ë¥˜", "ê°€ì••ë¥˜", "ì‹ íƒ", "ì²´ë‚©", "ìœ„ë°˜ê±´ì¶•ë¬¼", "ì´ì¤‘ê³„ì•½"]
    found_keywords = []
    # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ í‚¤ì›Œë“œ ê²€ìƒ‰ ìˆ˜í–‰
    if text and isinstance(text, str):
        for keyword in risk_keywords:
            if keyword in text:
                found_keywords.append(keyword)
    return found_keywords

def generate_explanation(risk_label, keywords):
    """íŒë‹¨ ê²°ê³¼ì™€ í‚¤ì›Œë“œë¥¼ ì¡°í•©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ì„¤ëª… ë¬¸ì¥ì„ ìƒì„±"""
    
    intro = f"í•´ë‹¹ ë¬¸ì„œë¥¼ ë¶„ì„í•œ ê²°ê³¼, '{risk_label}'ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.\n"
    
    if not keywords:
        reason = "íŠ¹ë³„íˆ ê°ì§€ëœ ìœ„í—˜ í‚¤ì›Œë“œëŠ” ì—†ì§€ë§Œ, ê³„ì•½ì„œì˜ ì „ì²´ì ì¸ ë‚´ìš©ì„ ê²€í† í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
    else:
        keyword_str = ", ".join(keywords)
        reason = f"íŠ¹íˆ ë¬¸ì„œì—ì„œ '{keyword_str}' ë“±ì˜ ë‹¨ì–´ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. "

        if "ê·¼ì €ë‹¹" in keywords:
            reason += "ì´ëŠ” ì§‘ì£¼ì¸ì´ ì§‘ì„ ë‹´ë³´ë¡œ ëŒ€ì¶œì„ ë°›ì€ ìƒíƒœì¼ ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. "
        if "ì••ë¥˜" in keywords:
            reason += "ì„¸ê¸ˆ ì²´ë‚© ë“±ì˜ ì´ìœ ë¡œ ìì‚°ì´ ë™ê²°ë˜ì—ˆì„ ìˆ˜ ìˆì–´ ë§¤ìš° ìœ„í—˜í•©ë‹ˆë‹¤. "

    recommendation = "\nê³„ì•½ ì§„í–‰ ì „, í•´ë‹¹ ë‚´ìš©ì— ëŒ€í•´ ë¶€ë™ì‚° ì „ë¬¸ê°€ë‚˜ ë²•ë¥  ì „ë¬¸ê°€ì™€ ë°˜ë“œì‹œ ìƒë‹´í•˜ì‹œëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤."
    
    return intro + reason + recommendation

# --- 3. ìˆ˜ì •ë  ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---

if __name__ == "__main__":
    target_folder_path = r'D:\test_data'
    
    image_extensions = ('*.jpg', '*.jpeg', '*.png', '*.bmp', '*.gif')
    file_list = []
    for ext in image_extensions:
        file_list.extend(glob.glob(os.path.join(target_folder_path, ext)))

    if not file_list:
        print(f"'{target_folder_path}' í´ë”ì—ì„œ ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"ì´ {len(file_list)}ê°œì˜ íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
        
        for file_path in file_list:
            print(f"\n{'='*50}\n--- ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘: {os.path.basename(file_path)} ---\n")
            
            extracted_text = extract_text_from_image(file_path)
            
            # OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸
            if not extracted_text or "ì˜¤ë¥˜ ë°œìƒ" in extracted_text:
                print("âš ï¸ ë¶„ì„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                if extracted_text:
                    print(extracted_text) # ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥
            else:
                # 1. KLUE ëª¨ë¸ë¡œ ìœ„í—˜ë„ íŒë‹¨
                risk_label = predict_risk(extracted_text)
                
                # 2. OCR í…ìŠ¤íŠ¸ì—ì„œ ê·¼ê±° í‚¤ì›Œë“œ ì°¾ê¸°
                keywords = find_risk_keywords(extracted_text)
                
                # AIê°€ 'ìœ„í—˜'ìœ¼ë¡œ íŒë‹¨í–ˆìœ¼ë‚˜, ëª…í™•í•œ í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš° 'ì£¼ì˜'ë¡œ ì•ˆë‚´
                if "ìœ„í—˜" in risk_label and not keywords:
                    print(f"í•´ë‹¹ ë¬¸ì„œë¥¼ ë¶„ì„í•œ ê²°ê³¼, 'âš ï¸ ì£¼ì˜'ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n")
                    print("AIê°€ ìœ„í—˜ ê°€ëŠ¥ì„±ì´ ìˆëŠ” íŒ¨í„´ì„ ê°ì§€í–ˆìœ¼ë‚˜, ëª…í™•í•œ ìœ„í—˜ í‚¤ì›Œë“œëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    print("ê³„ì•½ì„œì˜ ì „ì²´ì ì¸ ë‚´ìš©ì„ ì „ë¬¸ê°€ì™€ í•¨ê»˜ ê¼¼ê¼¼íˆ ê²€í† í•´ ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.")

                else :
                    # 3. ìì—°ìŠ¤ëŸ¬ìš´ ì„¤ëª… ë¬¸ì¥ ìƒì„±
                    explanation = generate_explanation(risk_label, keywords)
                
                    print("--- ìµœì¢… ë¶„ì„ ê²°ê³¼ ---")
                    print(explanation)
        
        print(f"\n{'='*50}\nëª¨ë“  íŒŒì¼ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
